{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare hyperspectral data for regression in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spectralpy reads in data as a 3d array. It is unclear to me if we need to reformat this into 2D before running regression or can just take a slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectral.io.envi as envi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = glob.glob(\"/scratch2/NSF_GWAS/macroPhor_Array/T16_DEV_genes/EA/wk7/*.hdr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = files_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will go into it's own file, called hypercube, and be imported by adding to ```__init__.py```:<br>\n",
    "```from .hypercube import Hypercube```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypercube:\n",
    "    \"\"\"A 3D hypercube containing spectra for each pixel\n",
    "    \n",
    "    :param value: value to set as the ``attribute`` attribute\n",
    "    :ivar attribute: contains the contents of ``values`` passed as init\n",
    "    \n",
    "    \"\"\"\n",
    "    i = 12345\n",
    "\n",
    "    def f(self):\n",
    "        return 'hello world'\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        # Define attribute with contents of the value param\n",
    "        self.hypercube = envi.open(file_path)\n",
    "        self.wavelengths = envi.read_envi_header(file_path)['wavelength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header parameter names converted to lower case.\n",
      "Header parameter names converted to lower case.\n"
     ]
    }
   ],
   "source": [
    "test_cube = Hypercube(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now to create another class (a child class?) that has this hypercube collapsed into a 2D format with which we can perform matrix algebra operations for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, let's figure out how to collapse that hypercube into 2D with numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the dimensions of our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1571, 1419, 318)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cube.hypercube.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is (n, m, lambda), where each n, m pixel has a signal intensity lambda. Flattening of this is similar to the problem described here (https://stackoverflow.com/questions/32838802/numpy-with-python-convert-3d-array-to-2d) but with hyperspectral instead of RGB data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cube = np.asarray(test_cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cube.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BilFile' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5c1a9afc1ba6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_cube_flattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypercube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'BilFile' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "test_cube_flattened = test_cube.reshape(newshape = ((test_cube.shape[0]*test_cube.shape[1], test_cube.shape[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apparently the BilFile object still isn't read into memory. Need to read it in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_bands() missing 1 required positional argument: 'bands'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-87dbf5903095>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypercube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_bands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: read_bands() missing 1 required positional argument: 'bands'"
     ]
    }
   ],
   "source": [
    "bands = test_cube.hypercube.read_bands()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To follow DRY principle, take earlier code for getting wavelengths (in build_X) and convert to function that is used both here and in build_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wavelengths(file_path):\n",
    "    h = envi.read_envi_header(file_path)\n",
    "    wavelengths = h['wavelength']\n",
    "    return(wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header parameter names converted to lower case.\n"
     ]
    }
   ],
   "source": [
    "wavelengths = read_wavelengths(file_path = file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We also need to subset wavelengths to only the desired wavelengths. Use same function as before for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_desired_indices(wavelengths, min_desired_wavelength, max_desired_wavelength):\n",
    "    wavelengths = np.asarray(wavelengths)\n",
    "    # https://stackoverflow.com/questions/13869173/numpy-find-index-of-the-elements-within-range\n",
    "    wavelength_indices_desired = np.where(np.logical_and(wavelengths.astype(float)>=min_desired_wavelength,\n",
    "                                                          wavelengths.astype(float)<=max_desired_wavelength))\n",
    "    return(wavelength_indices_desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_indices = find_desired_indices(wavelengths, 550, 650)\n",
    "subset_wavelengths = np.array(wavelengths)[subset_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### It should be much quicker to load in bands between 550-650 than ALL bands. Let's compare the relative speeds of each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first look at the documentation to figure out how to input our desired bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method read_bands in module spectral.io.bilfile:\n",
      "\n",
      "read_bands(bands, use_memmap=True) method of spectral.io.bilfile.BilFile instance\n",
      "    Reads multiple bands from the image.\n",
      "    \n",
      "    Arguments:\n",
      "    \n",
      "        `bands` (list of ints):\n",
      "    \n",
      "            Indices of bands to read.\n",
      "    \n",
      "        `use_memmap` (bool, default True):\n",
      "    \n",
      "            Specifies whether the file's memmap interface should be used\n",
      "            to read the data. Setting this arg to True only has an effect\n",
      "            if a memmap is being used (i.e., if `img.using_memmap` is True).\n",
      "            \n",
      "    Returns:\n",
      "    \n",
      "       :class:`numpy.ndarray`\n",
      "    \n",
      "            An `MxNxL` array of values for the specified bands. `M` and `N`\n",
      "            are the number of rows & columns in the image and `L` equals\n",
      "            len(`bands`).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(test_cube.hypercube.read_bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to benchmark reading in 550-650nm bands vs. all bands..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-2d0c40b7ab59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtime_pre_read_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbands_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypercube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_bands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbands\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtime_post_read_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_pre_read_partial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch2/NSF_GWAS/anaconda3/lib/python3.7/site-packages/spectral/io/bilfile.py\u001b[0m in \u001b[0;36mread_bands\u001b[0;34m(self, bands, use_memmap)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memmap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_memmap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_memmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "time_pre_read_partial = time.perf_counter()\n",
    "bands_partial = test_cube.hypercube.read_bands(bands=subset_indices)\n",
    "time_post_read_partial = time.perf_counter() - time_pre_read_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "        134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "        147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
       "        160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
       "        173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
       "        186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
       "        199, 200]),)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133,\n",
       "       134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146,\n",
       "       147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159,\n",
       "       160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172,\n",
       "       173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185,\n",
       "       186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
       "       199, 200])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(subset_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahhh... the object subset_indices is not an array, but a tuple containing an array. What we want is the array at the ```[0]``` position of this object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try again with ```subset_indices[0]``` instead of ```subset_indices```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pre_read_partial = time.perf_counter()\n",
    "bands_partial = test_cube.hypercube.read_bands(bands=subset_indices[0])\n",
    "time_post_read_partial = time.perf_counter() - time_pre_read_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to define an array of every wavelength index (note: NOT every wavelength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices =  np.arange(0, len(wavelengths), step = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. now let's pass this object to the ```bands``` argument of ```read_bands```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_pre_read_full = time.perf_counter()\n",
    "bands_full = test_cube.hypercube.read_bands(bands=all_indices)\n",
    "time_post_read_full = time.perf_counter() - time_pre_read_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare the runtimes recorded...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading wavelengths only within range 550-650nm, ran in this many seconds...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35270235361531377\n"
     ]
    }
   ],
   "source": [
    "print(time_post_read_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading all wavelengths..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.346348533872515\n"
     ]
    }
   ],
   "source": [
    "print(time_post_read_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are both pretty fast. Let's make sure the full objects are actually loaded into memory...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1571, 1419, 80)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands_partial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99, 116, 122, 101, 111, 114, 118, 112, 104],\n",
       "       [ 99, 118, 120, 117, 110, 109, 126, 107, 117],\n",
       "       [111, 111, 123,  97, 114, 112, 103, 112, 104],\n",
       "       [110, 113, 123, 119, 109, 115, 110,  99, 115],\n",
       "       [ 96, 112, 106, 120, 101, 106, 110, 110, 117],\n",
       "       [108, 112, 116, 121, 113, 129, 120, 110, 118],\n",
       "       [103, 109, 106, 109, 107, 114, 125, 114, 114],\n",
       "       [107, 110, 118, 117, 112, 113,  93, 107, 113],\n",
       "       [104, 103, 121, 121, 106, 109, 108, 117, 118]], dtype=uint16)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands_partial[1:10,1:10,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty sure it is! Note, these runtimes are at least an order of magnitude faster than ```hyperSpec::read.ENVI()``` in ```R```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now to integrate this complete loading of data into the hypercube...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hypercube:\n",
    "    \"\"\"A 3D hypercube containing spectra for each pixel\n",
    "    \n",
    "    :param file_path: A string indicating the path to the header file (in ENVI .hdr format) corresponding to the hyperspectral image file (in ENVI .raw format) to be read in\n",
    "    :param min_desired_wavelength: A numeric value indicating a threshold BELOW which spectral data is excluded\n",
    "    :param max_desired_wavelength: A numeric value indicating a threshold ABOVE which spectral data is excluded\n",
    "    :param hypercube: 3D numpy array containing a spectra for each pixel\n",
    "    :ivar wavelengths: contains the contents of ``wavelengths`` passed as init and subsequently trimmed to desired range\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_path, min_desired_wavelength, max_desired_wavelength):\n",
    "        # Define attribute with contents of the value param\n",
    "        \n",
    "        all_wavelengths = read_wavelengths(file_path)\n",
    "        subset_indices = find_desired_indices(all_wavelengths, min_desired_wavelength, max_desired_wavelength)\n",
    "        subset_wavelengths = np.array(all_wavelengths)[subset_indices[0]]\n",
    "        \n",
    "        self.hypercube = test_cube.hypercube.read_bands(bands=subset_indices[0])\n",
    "        self.wavelengths = subset_wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_wavelengths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-71f13e49a7ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m my_cube = Hypercube(file_path = file_path,\n\u001b[1;32m      3\u001b[0m                     \u001b[0mmin_desired_wavelength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m550\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     max_desired_wavelength = 650)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtime_post_read_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_pre_read_partial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-8e73ee62168e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file_path, min_desired_wavelength, max_desired_wavelength)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Define attribute with contents of the value param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mall_wavelengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_wavelengths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0msubset_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_desired_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_wavelengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_desired_wavelength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_desired_wavelength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0msubset_wavelengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_wavelengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubset_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_wavelengths' is not defined"
     ]
    }
   ],
   "source": [
    "time_pre_read_partial = time.perf_counter()\n",
    "my_cube = Hypercube(file_path = file_path,\n",
    "                    min_desired_wavelength = 550,\n",
    "                    max_desired_wavelength = 650)\n",
    "time_post_read_partial = time.perf_counter() - time_pre_read_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seconds it ran in (should be ~0.3s as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3633701531216502\n"
     ]
    }
   ],
   "source": [
    "print(time_post_read_partial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Now for some more checks. Let's make sure we have the same # bands in both the matrix and the wavelength array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_cube.wavelengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1571, 1419, 80)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cube.hypercube.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's flatten this into the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_cube' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1c9d65c7e107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_cube_flattened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cube\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'my_cube' is not defined"
     ]
    }
   ],
   "source": [
    "test_cube_flattened = my_cube.reshape(newshape = ((test_cube.shape[0]*test_cube.shape[1], test_cube.shape[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All good! Ready to work on documentation for the pre-regression functions, and ultimately regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
